# ðŸ‘‹ Hello, I'm ZHANG Erli!

## ðŸ‘¤ About me
I am a final-year undergraduate at Nanyang Technological University ðŸ‡¸ðŸ‡¬, majoring in Computer Science. My current research interests include **Large Multimodal Models**,  **Visual Quality Assessment** and **AI in Healthcare**. 

I'm currently applying for PhD programs starting in 2024 Fall!

- **Resume:** [Resume](https://github.com/ZhangErliCarl/ZhangErliCarl/blob/d9101d841202d5aff85f377b96e659a974600480/resume.pdf)
- **Homepage:** [Homepage](https://zhangerlicarl.github.io/)
- **Google Scholar:** [Profile](https://scholar.google.com/citations?user=gfjYZKMAAAAJ&hl=en-US)
- **LinkedIn:** [LinkedIn](https://www.linkedin.com/in/zhang-erli/)

## ðŸ“– Publications
  
### [Q-Bench: Multi-Modality Benchmarking](https://github.com/Q-Future/Q-Bench)
- **Conference:** ICLR 2024 (spotlight)
- **Description:** A benchmark for multi-modality LLMs on low-level vision and visual quality assessment.
- ðŸ“– [Paper](https://arxiv.org/abs/2309.14181)

### [MaxVQA/MaxWell: Towards Explainable VQA](https://github.com/VQAssessment/MaxVQA)
- **Conference:** ACMMM 2023 (oral)
- **Description:** Introduced a 16-dimensional VQA Dataset and Method for a more explainable VQA.
- ðŸ“– [Paper](https://dl.acm.org/doi/pdf/10.1145/3581783.3611737)

### [DOVER: NR-VQA Method](https://github.com/VQAssessment/DOVER)
- **Conference:** ICCV 2023
- **Description:** A state-of-the-art NR-VQA method that predicts disentangled aesthetic and technical quality.
- ðŸ“– [Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf)
- **Demo:** [Demo](https://colab.research.google.com/github/taskswithcode/DOVER/blob/master/TWCDOVER.ipynb)

## ðŸ“¬ Contact Me
- **Email:** zhangerlicarl@gmail.com or ezhang005@e.ntu.edu.sg
- **Twitter:** [@zhang_erli](https://twitter.com/zhang_erli)
